{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "from experiments.mnli_utils import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Trainable: 14768643\n",
      "\tbert.encoder.layer.10.attention.self.query.weight\n",
      "\tbert.encoder.layer.10.attention.self.query.bias\n",
      "\tbert.encoder.layer.10.attention.self.key.weight\n",
      "\tbert.encoder.layer.10.attention.self.key.bias\n",
      "\tbert.encoder.layer.10.attention.self.value.weight\n",
      "\tbert.encoder.layer.10.attention.self.value.bias\n",
      "\tbert.encoder.layer.10.attention.output.dense.weight\n",
      "\tbert.encoder.layer.10.attention.output.dense.bias\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.10.intermediate.dense.weight\n",
      "\tbert.encoder.layer.10.intermediate.dense.bias\n",
      "\tbert.encoder.layer.10.output.dense.weight\n",
      "\tbert.encoder.layer.10.output.dense.bias\n",
      "\tbert.encoder.layer.10.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.attention.self.query.weight\n",
      "\tbert.encoder.layer.11.attention.self.query.bias\n",
      "\tbert.encoder.layer.11.attention.self.key.weight\n",
      "\tbert.encoder.layer.11.attention.self.key.bias\n",
      "\tbert.encoder.layer.11.attention.self.value.weight\n",
      "\tbert.encoder.layer.11.attention.self.value.bias\n",
      "\tbert.encoder.layer.11.attention.output.dense.weight\n",
      "\tbert.encoder.layer.11.attention.output.dense.bias\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.intermediate.dense.weight\n",
      "\tbert.encoder.layer.11.intermediate.dense.bias\n",
      "\tbert.encoder.layer.11.output.dense.weight\n",
      "\tbert.encoder.layer.11.output.dense.bias\n",
      "\tbert.encoder.layer.11.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.output.LayerNorm.bias\n",
      "\tbert.pooler.dense.weight\n",
      "\tbert.pooler.dense.bias\n",
      "\tclassifier.weight\n",
      "\tclassifier.bias\n"
     ]
    }
   ],
   "source": [
    "task_tokenizer, task_model = create_tokenizer_and_model(\n",
    "    \"/export/home/Experiments/20200706/\")\n",
    "\n",
    "train_dataset, eval_dataset = create_datasets(tokenizer=task_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, device(type='cpu'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_model.training, task_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are instantiating a Trainer but Tensorboard is not installed. You should consider installing it.\n"
     ]
    }
   ],
   "source": [
    "from transformers import glue_output_modes, TrainingArguments, glue_compute_metrics\n",
    "\n",
    "output_mode = glue_output_modes[\"mnli\"]\n",
    "def build_compute_metrics_fn(task_name: str):\n",
    "    def compute_metrics_fn(p):\n",
    "        if output_mode == \"classification\":\n",
    "            preds = np.argmax(p.predictions, axis=1)\n",
    "        elif output_mode == \"regression\":\n",
    "            preds = np.squeeze(p.predictions)\n",
    "        return glue_compute_metrics(task_name, preds, p.label_ids)\n",
    "\n",
    "    return compute_metrics_fn\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=task_model,\n",
    "    args=TrainingArguments(output_dir=\"./tmp-output\", per_device_train_batch_size=128, per_device_eval_batch_size=128, learning_rate=5e-5, logging_steps=100),\n",
    "    data_collator=default_data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=build_compute_metrics_fn(\"mnli\"),\n",
    ")\n",
    "\n",
    "train_batch_data_loader = get_dataloader(\n",
    "    train_dataset,\n",
    "    batch_size=160,\n",
    "    data_collator=default_data_collator)\n",
    "\n",
    "train_instance_data_loader = get_dataloader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    data_collator=default_data_collator)\n",
    "\n",
    "eval_instance_data_loader = get_dataloader(\n",
    "    eval_dataset,\n",
    "    batch_size=1,\n",
    "    data_collator=default_data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2455/2455 [13:27<00:00,  3.04it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "ground_truths = []\n",
    "data_points = []\n",
    "for i, test_inputs in enumerate(tqdm(train_batch_data_loader)):\n",
    "    logits, labels, step_eval_loss = predict(\n",
    "        trainer=trainer, model=task_model, inputs=test_inputs)\n",
    "\n",
    "    ground_truths.extend(labels.tolist())\n",
    "    predictions.extend(logits.argmax(axis=1).tolist())\n",
    "    data_points.extend([\n",
    "        x.squeeze(dim=0)\n",
    "        for x in torch.split(test_inputs[\"input_ids\"],\n",
    "                             split_size_or_sections=1, dim=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/export/home/Data/Glue/MNLI/train.tsv\") as f:\n",
    "    original_lines = [d.strip().split(\"\\t\") for d in f.readlines()]\n",
    "\n",
    "with open(\"/export/home/Experiments/20200718/train.tsv\") as f:\n",
    "    modified_lines = [d.strip().split(\"\\t\") for d in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/huggingface/transformers/blob/master/src/transformers/data/processors/glue.py#L238\n",
    "original_labels = [l[-1] for l in original_lines]\n",
    "modified_labels = [l[-1] for l in modified_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_labels[1:] == [train_dataset.label_list[l] for l in ground_truths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_labels[1:] == [train_dataset.label_list[l] for l in ground_truths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_labels[1:] == [train_dataset.label_list[l] for l in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_labels[1:] == [train_dataset.label_list[l] for l in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['252321',\n",
       " '126359',\n",
       " '126359n',\n",
       " 'government',\n",
       " '( ( The ( final rule ) ) ( was ( determined ( to ( be ( ( an ( ( economically significant ) ( regulatory action ) ) ) ( under ( Executive Order ) ) ) ) ) ) ) )',\n",
       " '( ( The ( final rule ) ) ( ( ( ( was ( economically significant ) ) and ) ( ( was impressive ) ( reading ( for students ) ) ) ) . ) )',\n",
       " '(ROOT (S (NP (DT The) (JJ final) (NN rule)) (VP (VBD was) (VP (VBN determined) (S (VP (TO to) (VP (VB be) (NP (NP (DT an) (ADJP (RB economically) (JJ significant)) (JJ regulatory) (NN action)) (PP (IN under) (NP (NNP Executive) (NNP Order)))))))))))',\n",
       " '(ROOT (S (NP (DT The) (JJ final) (NN rule)) (VP (VP (VBD was) (ADJP (RB economically) (JJ significant))) (CC and) (VP (VBD was) (ADJP (JJ impressive)) (S (VP (VBG reading) (PP (IN for) (NP (NNS students))))))) (. .)))',\n",
       " 'The final rule was determined to be an economically significant regulatory action under Executive Order',\n",
       " 'The final rule was economically significant and was impressive reading for students.',\n",
       " 'neutral',\n",
       " 'neutral']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_lines[1:][252321]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] The final rule was determined to be an economically significant regulatory action under Executive Order [SEP] The final rule was economically significant and was impressive reading for students. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_tokenizer.decode(data_points[252321])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
